{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approaching Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>372143</th>\n",
       "      <td>372143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>a12077f95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Master</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>o</td>\n",
       "      <td>Q</td>\n",
       "      <td>pB</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14439</th>\n",
       "      <td>14439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>fdf9297f6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Warm</td>\n",
       "      <td>m</td>\n",
       "      <td>T</td>\n",
       "      <td>Nh</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68841</th>\n",
       "      <td>68841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Square</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>China</td>\n",
       "      <td>...</td>\n",
       "      <td>30db15878</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Warm</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ly</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314450</th>\n",
       "      <td>314450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>Lion</td>\n",
       "      <td>China</td>\n",
       "      <td>...</td>\n",
       "      <td>e74d93bc8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xG</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345795</th>\n",
       "      <td>345795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>ede9f9f4d</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Hot</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141243</th>\n",
       "      <td>141243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Lion</td>\n",
       "      <td>India</td>\n",
       "      <td>...</td>\n",
       "      <td>2a27c8fde</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Hot</td>\n",
       "      <td>b</td>\n",
       "      <td>T</td>\n",
       "      <td>HK</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153986</th>\n",
       "      <td>153986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>...</td>\n",
       "      <td>580e3caf1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Warm</td>\n",
       "      <td>e</td>\n",
       "      <td>E</td>\n",
       "      <td>AI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66024</th>\n",
       "      <td>66024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>de54260a1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Master</td>\n",
       "      <td>Warm</td>\n",
       "      <td>m</td>\n",
       "      <td>A</td>\n",
       "      <td>mD</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568940</th>\n",
       "      <td>568940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>5cb7f1328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>n</td>\n",
       "      <td>A</td>\n",
       "      <td>gL</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361962</th>\n",
       "      <td>361962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Square</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>7d9542273</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>oU</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0      nom_1    nom_2  \\\n",
       "372143  372143    1.0    0.0    0.0     F     N  Blue   Triangle      Dog   \n",
       "14439    14439    0.0    1.0    1.0     F     Y   Red    Polygon  Hamster   \n",
       "68841    68841    0.0    0.0    0.0     T     N  Blue     Square  Hamster   \n",
       "314450  314450    0.0    0.0    0.0     F     N  Blue    Polygon     Lion   \n",
       "345795  345795    0.0    0.0    0.0     F     N  Blue     Circle  Hamster   \n",
       "141243  141243    0.0    0.0    0.0     F     N   Red   Triangle     Lion   \n",
       "153986  153986    0.0    0.0    0.0     T     Y   Red     Circle  Hamster   \n",
       "66024    66024    1.0    0.0    0.0     F     Y   Red  Trapezoid  Hamster   \n",
       "568940  568940    1.0    0.0    NaN     T     N   Red     Circle  Hamster   \n",
       "361962  361962    0.0    0.0    0.0     T     N   Red     Square  Axolotl   \n",
       "\n",
       "             nom_3  ...      nom_9 ord_0        ord_1     ord_2 ord_3 ord_4  \\\n",
       "372143      Canada  ...  a12077f95   1.0       Master  Freezing     o     Q   \n",
       "14439      Finland  ...  fdf9297f6   2.0  Contributor      Warm     m     T   \n",
       "68841        China  ...  30db15878   3.0       Expert      Warm     m   NaN   \n",
       "314450       China  ...  e74d93bc8   2.0       Novice  Freezing     o   NaN   \n",
       "345795      Russia  ...  ede9f9f4d   3.0       Novice       Hot     b   NaN   \n",
       "141243       India  ...  2a27c8fde   3.0  Contributor       Hot     b     T   \n",
       "153986  Costa Rica  ...  580e3caf1   1.0  Grandmaster      Warm     e     E   \n",
       "66024       Russia  ...  de54260a1   1.0       Master      Warm     m     A   \n",
       "568940     Finland  ...  5cb7f1328   1.0  Contributor  Freezing     n     A   \n",
       "361962      Russia  ...  7d9542273   2.0       Expert  Freezing     b     B   \n",
       "\n",
       "        ord_5  day month target  \n",
       "372143     pB  6.0   5.0      0  \n",
       "14439      Nh  5.0  11.0      0  \n",
       "68841      ly  6.0   6.0      0  \n",
       "314450     xG  3.0   7.0      1  \n",
       "345795     mP  1.0  12.0      0  \n",
       "141243     HK  6.0  12.0      0  \n",
       "153986     AI  3.0   3.0      0  \n",
       "66024      mD  5.0   8.0      0  \n",
       "568940     gL  4.0  12.0      0  \n",
       "361962     oU  6.0  12.0      0  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(\"cat_train.csv\")\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hot', 'Warm', 'Freezing', 'Lava Hot', 'Cold', 'Boiling Hot', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View unique values in column ord_2\n",
    "df['ord_2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the value counts before mapping\n",
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most important ways to handle categorical variables\n",
    "1. Label Encoding\n",
    "2. Sparse Matrices\n",
    "3. One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"Freezing\": 0,\n",
    "    \"Warm\": 1,\n",
    "    \"Cold\": 2,\n",
    "    \"Boiling Hot\": 3,\n",
    "    \"Hot\": 4,\n",
    "    \"Lava Hot\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    142726\n",
       "1.0    124239\n",
       "2.0     97822\n",
       "3.0     84790\n",
       "4.0     67508\n",
       "5.0     64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encoding - Convert categories to numbers\n",
    "df.loc[:, \"ord_2\"] = df.ord_2.map(mapping)\n",
    "\n",
    "# View the value counts after mapping\n",
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>02e7c8990</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>U</td>\n",
       "      <td>Pw</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Star</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>f37df64af</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>6</td>\n",
       "      <td>e</td>\n",
       "      <td>X</td>\n",
       "      <td>pE</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>P</td>\n",
       "      <td>eN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>f9d456e57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Novice</td>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>...</td>\n",
       "      <td>c5361037c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>1</td>\n",
       "      <td>h</td>\n",
       "      <td>C</td>\n",
       "      <td>OZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0      nom_1    nom_2       nom_3  \\\n",
       "0   0    0.0    0.0    0.0     F     N   Red  Trapezoid  Hamster      Russia   \n",
       "1   1    1.0    1.0    0.0     F     Y   Red       Star  Axolotl         NaN   \n",
       "2   2    0.0    1.0    0.0     F     N   Red        NaN  Hamster      Canada   \n",
       "3   3    NaN    0.0    0.0     F     N   Red     Circle  Hamster     Finland   \n",
       "4   4    0.0    NaN    0.0     T     N   Red   Triangle  Hamster  Costa Rica   \n",
       "\n",
       "   ...      nom_9 ord_0        ord_1 ord_2 ord_3 ord_4  ord_5  day  month  \\\n",
       "0  ...  02e7c8990   3.0  Contributor     3     c     U     Pw  6.0    3.0   \n",
       "1  ...  f37df64af   3.0  Grandmaster     6     e     X     pE  7.0    7.0   \n",
       "2  ...        NaN   3.0          NaN     2     n     P     eN  5.0    9.0   \n",
       "3  ...  f9d456e57   1.0       Novice     4     a     C    NaN  3.0    3.0   \n",
       "4  ...  c5361037c   3.0  Grandmaster     1     h     C     OZ  5.0   12.0   \n",
       "\n",
       "  target  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encoding using scikit-learn\n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "\n",
    "# read the data\n",
    "df = pd.read_csv(\"cat_train.csv\")\n",
    "\n",
    "# fill the NaN values in ord_2 column (because LabelEncoder of scikit-learn does not handle NaN values)\n",
    "df.loc[:, \"ord_2\"] = df.ord_2.fillna(\"NONE\")\n",
    "\n",
    "# initialize LabelEncoder\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "\n",
    "# fit label encoder and transform values on ord_2 column\n",
    "# P.S.: do not use this directly, fit first and then transform\n",
    "df.loc[:, \"ord_2\"] = lbl_enc.fit_transform(df.ord_2.values)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "# size of a numpy array\n",
    "import numpy as np\n",
    "\n",
    "# create our example feature matrix\n",
    "example = np.array(\n",
    "    [\n",
    "        [0, 0, 1],\n",
    "        [1, 0, 0],\n",
    "        [1, 0, 1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# print size in bytes\n",
    "print(example.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# convert numpy array to sparse matrix\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "# create our example feature matrix\n",
    "example = np.array(\n",
    "    [\n",
    "        [0, 0, 1],\n",
    "        [1, 0, 0],\n",
    "        [1, 0, 1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# convert numpy array to sparse CSR matrix\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "\n",
    "# print size of this sparse matrix\n",
    "print(sparse_example.data.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "# total size of sparse csr matrix\n",
    "print(\n",
    "    sparse_example.data.nbytes +\n",
    "    sparse_example.indptr.nbytes + \n",
    "    sparse_example.indices.nbytes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dense array: 4000000000\n",
      "Size of sparse array: 200001588\n",
      "Full size of sparse array: 400043180\n"
     ]
    }
   ],
   "source": [
    "# Comparison of sizes of dense and sparse arrays\n",
    "import numpy as np \n",
    "from scipy import sparse \n",
    "\n",
    "# number of rows\n",
    "n_rows = 10000\n",
    "\n",
    "# number of columns\n",
    "n_cols = 100000\n",
    "\n",
    "# create random binary matrix with only 5% values as 1s\n",
    "example = np.random.binomial(1, p=0.05, size=(n_rows, n_cols))\n",
    "\n",
    "# print size in bytes\n",
    "print(f\"Size of dense array: {example.nbytes}\")\n",
    "\n",
    "# convert numpy array to sparse CSR matrix\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "\n",
    "# print size of this sparse matrix\n",
    "print(f\"Size of sparse array: {sparse_example.data.nbytes}\")\n",
    "\n",
    "full_size = (\n",
    "    sparse_example.data.nbytes +\n",
    "    sparse_example.indptr.nbytes + \n",
    "    sparse_example.indices.nbytes\n",
    ")\n",
    "\n",
    "# print full size of this sparse matrix\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dense array: 72\n",
      "Size of sparse array: 12\n",
      "Full size of sparse array: 40\n"
     ]
    }
   ],
   "source": [
    "# Comparison of sizes of dense and binarized arrays\n",
    "import numpy as np \n",
    "from scipy import sparse \n",
    "\n",
    "# create binary matrix\n",
    "example = np.array(\n",
    "    [\n",
    "        [0, 0, 0, 0, 1, 0],\n",
    "        [0, 1, 0, 0, 0, 0],\n",
    "        [1, 0, 0, 0, 0, 0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# print size in bytes\n",
    "print(f\"Size of dense array: {example.nbytes}\")\n",
    "\n",
    "# convert numpy array to sparse CSR matrix\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "\n",
    "# print size of this sparse matrix\n",
    "print(f\"Size of sparse array: {sparse_example.data.nbytes}\")\n",
    "\n",
    "full_size = (\n",
    "    sparse_example.data.nbytes +\n",
    "    sparse_example.indptr.nbytes + \n",
    "    sparse_example.indices.nbytes\n",
    ")\n",
    "\n",
    "# print full size of this sparse matrix\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dense array: 8000000000\n",
      "Size of sparse array: 8000000\n",
      "Full size of sparse array: 16000004\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn's OneHotEncoder to transform a much larger feature array with 1001 categories\n",
    "import numpy as np \n",
    "from sklearn import preprocessing\n",
    "\n",
    "# create random 1D array with 1001 different categories (int)\n",
    "example = np.random.randint(1000, size=1000000)\n",
    "\n",
    "# initialize OneHotEncoder from scikit-learn\n",
    "# keep sparse = False to get dense array\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "\n",
    "# fit and transform data with dense one hot encoder\n",
    "ohe_example = ohe.fit_transform(example.reshape(-1, 1))\n",
    "\n",
    "# print size in bytes for dense array\n",
    "print(f\"Size of dense array: {ohe_example.nbytes}\")\n",
    "\n",
    "# initialize OneHotEncoder from scikit-learn\n",
    "# keep sparse = True to get sparse array\n",
    "ohe = preprocessing.OneHotEncoder(sparse=True)\n",
    "\n",
    "# fit and transform data with sparse one hot encoder\n",
    "ohe_example = ohe.fit_transform(example.reshape(-1, 1))\n",
    "\n",
    "# print size in bytes for sparse array\n",
    "print(f\"Size of sparse array: {ohe_example.data.nbytes}\")\n",
    "\n",
    "full_size = (\n",
    "    ohe_example.data.nbytes +\n",
    "    ohe_example.indptr.nbytes +\n",
    "    ohe_example.indices.nbytes\n",
    ")\n",
    "\n",
    "# print full size of this sparse matrix\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ways to handle categorical variables:\n",
    "\n",
    "#### - Converting categorical variables to numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84790, 25)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of dataframe where 'ord_2' column has value 'Boiling Hot'\n",
    "import pandas as pd \n",
    "df = pd.read_csv(\"cat_train.csv\")\n",
    "df[df.ord_2 == 'Boiling Hot'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ord_2\n",
       "Boiling Hot     84790\n",
       "Cold            97822\n",
       "Freezing       142726\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "Warm           124239\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate above with pandas groupby function\n",
    "df.groupby(\"ord_2\")[\"id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          67508.0\n",
       "1         124239.0\n",
       "2         142726.0\n",
       "3          64840.0\n",
       "4          97822.0\n",
       "            ...   \n",
       "599995    142726.0\n",
       "599996     84790.0\n",
       "599997    142726.0\n",
       "599998    124239.0\n",
       "599999     84790.0\n",
       "Name: id, Length: 600000, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace ord_2 column with its count values to convert it to numerical column (using transform function of pandas)\n",
    "df.groupby(\"ord_2\")[\"id\"].transform(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>15634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Cold</td>\n",
       "      <td>17734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>26082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Hot</td>\n",
       "      <td>12428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>11919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Warm</td>\n",
       "      <td>22774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>19477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Cold</td>\n",
       "      <td>22956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>33249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Hot</td>\n",
       "      <td>15792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>15078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Warm</td>\n",
       "      <td>28900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>13623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>15464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>22818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Hot</td>\n",
       "      <td>10805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>10363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Warm</td>\n",
       "      <td>19899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Master</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>10800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Master</td>\n",
       "      <td>Cold</td>\n",
       "      <td>12364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Master</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>18035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Master</td>\n",
       "      <td>Hot</td>\n",
       "      <td>8594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Master</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>8209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Master</td>\n",
       "      <td>Warm</td>\n",
       "      <td>15734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>22718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Cold</td>\n",
       "      <td>26271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>38233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Hot</td>\n",
       "      <td>17850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>17373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Warm</td>\n",
       "      <td>33263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ord_1        ord_2  count\n",
       "0   Contributor  Boiling Hot  15634\n",
       "1   Contributor         Cold  17734\n",
       "2   Contributor     Freezing  26082\n",
       "3   Contributor          Hot  12428\n",
       "4   Contributor     Lava Hot  11919\n",
       "5   Contributor         Warm  22774\n",
       "6        Expert  Boiling Hot  19477\n",
       "7        Expert         Cold  22956\n",
       "8        Expert     Freezing  33249\n",
       "9        Expert          Hot  15792\n",
       "10       Expert     Lava Hot  15078\n",
       "11       Expert         Warm  28900\n",
       "12  Grandmaster  Boiling Hot  13623\n",
       "13  Grandmaster         Cold  15464\n",
       "14  Grandmaster     Freezing  22818\n",
       "15  Grandmaster          Hot  10805\n",
       "16  Grandmaster     Lava Hot  10363\n",
       "17  Grandmaster         Warm  19899\n",
       "18       Master  Boiling Hot  10800\n",
       "19       Master         Cold  12364\n",
       "20       Master     Freezing  18035\n",
       "21       Master          Hot   8594\n",
       "22       Master     Lava Hot   8209\n",
       "23       Master         Warm  15734\n",
       "24       Novice  Boiling Hot  22718\n",
       "25       Novice         Cold  26271\n",
       "26       Novice     Freezing  38233\n",
       "27       Novice          Hot  17850\n",
       "28       Novice     Lava Hot  17373\n",
       "29       Novice         Warm  33263"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also group by multiple columns and their counts\n",
    "df.groupby(\n",
    "    [\n",
    "        \"ord_1\",\n",
    "        \"ord_2\"\n",
    "    ]\n",
    ")[\"id\"].count().reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Create new categorical features from the existing ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Contributor_Hot\n",
       "1                Grandmaster_Warm\n",
       "2                    nan_Freezing\n",
       "3                 Novice_Lava Hot\n",
       "4                Grandmaster_Cold\n",
       "                   ...           \n",
       "599995            Novice_Freezing\n",
       "599996         Novice_Boiling Hot\n",
       "599997       Contributor_Freezing\n",
       "599998                Master_Warm\n",
       "599999    Contributor_Boiling Hot\n",
       "Name: new_feature, Length: 600000, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating names of ord_1 and ord_2 columns using an underscore\n",
    "df[\"new_feature\"] = (\n",
    "    df.ord_1.astype(str)\n",
    "    + \"_\"\n",
    "    + df.ord_2.astype(str)\n",
    ")\n",
    "df.new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "      <th>new_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Hot</td>\n",
       "      <td>c</td>\n",
       "      <td>U</td>\n",
       "      <td>Pw</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Contributor_Hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Star</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Warm</td>\n",
       "      <td>e</td>\n",
       "      <td>X</td>\n",
       "      <td>pE</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Grandmaster_Warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>n</td>\n",
       "      <td>P</td>\n",
       "      <td>eN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>nan_Freezing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Novice_Lava Hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>C</td>\n",
       "      <td>OZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Grandmaster_Cold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0      nom_1    nom_2       nom_3  \\\n",
       "0   0    0.0    0.0    0.0     F     N   Red  Trapezoid  Hamster      Russia   \n",
       "1   1    1.0    1.0    0.0     F     Y   Red       Star  Axolotl         NaN   \n",
       "2   2    0.0    1.0    0.0     F     N   Red        NaN  Hamster      Canada   \n",
       "3   3    NaN    0.0    0.0     F     N   Red     Circle  Hamster     Finland   \n",
       "4   4    0.0    NaN    0.0     T     N   Red   Triangle  Hamster  Costa Rica   \n",
       "\n",
       "   ... ord_0        ord_1     ord_2 ord_3 ord_4 ord_5  day month target  \\\n",
       "0  ...   3.0  Contributor       Hot     c     U    Pw  6.0   3.0      0   \n",
       "1  ...   3.0  Grandmaster      Warm     e     X    pE  7.0   7.0      0   \n",
       "2  ...   3.0          NaN  Freezing     n     P    eN  5.0   9.0      0   \n",
       "3  ...   1.0       Novice  Lava Hot     a     C   NaN  3.0   3.0      0   \n",
       "4  ...   3.0  Grandmaster      Cold     h     C    OZ  5.0  12.0      0   \n",
       "\n",
       "        new_feature  \n",
       "0   Contributor_Hot  \n",
       "1  Grandmaster_Warm  \n",
       "2      nan_Freezing  \n",
       "3   Novice_Lava Hot  \n",
       "4  Grandmaster_Cold  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Contributor_Hot_c\n",
       "1                Grandmaster_Warm_e\n",
       "2                    nan_Freezing_n\n",
       "3                 Novice_Lava Hot_a\n",
       "4                Grandmaster_Cold_h\n",
       "                    ...            \n",
       "599995            Novice_Freezing_a\n",
       "599996         Novice_Boiling Hot_n\n",
       "599997       Contributor_Freezing_n\n",
       "599998                Master_Warm_m\n",
       "599999    Contributor_Boiling Hot_b\n",
       "Name: new_feature, Length: 600000, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also combine three or four or even more features\n",
    "df[\"new_feature\"] = (\n",
    "    df.ord_1.astype(str)\n",
    "    + \"_\"\n",
    "    + df.ord_2.astype(str)\n",
    "    + \"_\"\n",
    "    + df.ord_3.astype(str)\n",
    ")\n",
    "df.new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling NaN values\n",
    "\n",
    "#### 1. Drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "bin_0     17894\n",
       "bin_1     18003\n",
       "bin_2     17930\n",
       "bin_3     18014\n",
       "bin_4     18047\n",
       "nom_0     18252\n",
       "nom_1     18156\n",
       "nom_2     18035\n",
       "nom_3     18121\n",
       "nom_4     18035\n",
       "nom_5     17778\n",
       "nom_6     18131\n",
       "nom_7     18003\n",
       "nom_8     17755\n",
       "nom_9     18073\n",
       "ord_0     18288\n",
       "ord_1     18041\n",
       "ord_2     18075\n",
       "ord_3     17916\n",
       "ord_4     17930\n",
       "ord_5     17713\n",
       "day       17952\n",
       "month     17988\n",
       "target        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"cat_train.csv\")\n",
    "\n",
    "# View the number of NaN values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "bin_0     0\n",
       "bin_1     0\n",
       "bin_2     0\n",
       "bin_3     0\n",
       "bin_4     0\n",
       "nom_0     0\n",
       "nom_1     0\n",
       "nom_2     0\n",
       "nom_3     0\n",
       "nom_4     0\n",
       "nom_5     0\n",
       "nom_6     0\n",
       "nom_7     0\n",
       "nom_8     0\n",
       "nom_9     0\n",
       "ord_0     0\n",
       "ord_1     0\n",
       "ord_2     0\n",
       "ord_3     0\n",
       "ord_4     0\n",
       "ord_5     0\n",
       "day       0\n",
       "month     0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop NaN values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# View number of NaN values\n",
    "df.isna().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Treat NaN values as a completely new category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"cat_train.csv\")\n",
    "\n",
    "# View the value counts of ord_2 column\n",
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "NONE            18075\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill NaNs with None\n",
    "df.ord_2.fillna(\"NONE\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding the train and test data\n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "\n",
    "# read training data\n",
    "train = pd.read_csv(\"cat_train.csv\")\n",
    "\n",
    "# read test data\n",
    "test = pd.read_csv(\"cat_test.csv\")\n",
    "\n",
    "# create a fake target column for test data\n",
    "# since this column doesn't exist\n",
    "test.loc[:, \"target\"] = -1\n",
    "\n",
    "# concatenate both training and test data\n",
    "data = pd.concat([train, test]).reset_index(drop=True)\n",
    "\n",
    "# make a list of features we are interested in \n",
    "# id and target is something we should not encode\n",
    "features = [x for x in train.columns if x not in [\"id\",\"target\"]]\n",
    "\n",
    "# loop over the feature list\n",
    "for feat in features:\n",
    "    # create a new instance of LabelEncoder for each feature\n",
    "    lbl_enc = preprocessing.LabelEncoder()\n",
    "    \n",
    "    # note the trick here\n",
    "    # since its categorical data, we fillna with a string\n",
    "    # and we convert all the data to string type\n",
    "    # so, no matter its int or float, its converted to string\n",
    "    # int/float but categorical !!!\n",
    "    temp_col = data[feat].fillna(\"NONE\").astype(str).values\n",
    "    \n",
    "    # we can use fit_transform here as we do not have any extra test data that we need to transform on separately\n",
    "    data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
    "    \n",
    "# split the training and test data again\n",
    "train = data[data.target != -1].reset_index(drop=True)\n",
    "test = data[data.target == -1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43034</th>\n",
       "      <td>43034</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431060</th>\n",
       "      <td>431060</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1599</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>143</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37982</th>\n",
       "      <td>37982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1660</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>169</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276099</th>\n",
       "      <td>276099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2123</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571987</th>\n",
       "      <td>571987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1460</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  bin_0  bin_1  bin_2  bin_3  bin_4  nom_0  nom_1  nom_2  nom_3  \\\n",
       "43034    43034      0      0      0      0      0      0      0      3      3   \n",
       "431060  431060      0      1      0      2      2      0      2      3      4   \n",
       "37982    37982      0      0      0      0      0      3      5      5      4   \n",
       "276099  276099      0      0      1      0      0      0      5      3      6   \n",
       "571987  571987      0      0      1      0      0      0      2      2      6   \n",
       "\n",
       "        ...  nom_9  ord_0  ord_1  ord_2  ord_3  ord_4  ord_5  day  month  \\\n",
       "43034   ...    307      0      5      1     11     16      3    1      4   \n",
       "431060  ...   1599      2      2      1      2      7    143    5      9   \n",
       "37982   ...   1660      1      1      6     14      6    169    5     10   \n",
       "276099  ...   2123      2      1      4      8     17     90    6      7   \n",
       "571987  ...   1460      2      1      6     14      5     62    4      9   \n",
       "\n",
       "        target  \n",
       "43034        0  \n",
       "431060       0  \n",
       "37982        0  \n",
       "276099       1  \n",
       "571987       0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View train data\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48489</th>\n",
       "      <td>648489</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1400</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60082</th>\n",
       "      <td>660082</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1439</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58524</th>\n",
       "      <td>658524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10190</th>\n",
       "      <td>610190</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1811</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>149</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228538</th>\n",
       "      <td>828538</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>407</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  bin_0  bin_1  bin_2  bin_3  bin_4  nom_0  nom_1  nom_2  nom_3  \\\n",
       "48489   648489      0      0      0      2      0      0      4      0      4   \n",
       "60082   660082      0      0      1      0      2      3      5      0      4   \n",
       "58524   658524      0      0      0      0      2      0      6      2      0   \n",
       "10190   610190      0      1      1      2      0      3      5      0      4   \n",
       "228538  828538      0      0      0      0      0      3      5      2      2   \n",
       "\n",
       "        ...  nom_9  ord_0  ord_1  ord_2  ord_3  ord_4  ord_5  day  month  \\\n",
       "48489   ...   1400      0      2      6      2     21     41    0      2   \n",
       "60082   ...   1439      2      1      1     15      2     21    6      5   \n",
       "58524   ...    258      1      1      1      6      5     46    4      9   \n",
       "10190   ...   1811      2      5      3      8     13    149    4      9   \n",
       "228538  ...    407      2      1      3      0     16    115    2     10   \n",
       "\n",
       "        target  \n",
       "48489       -1  \n",
       "60082       -1  \n",
       "58524       -1  \n",
       "10190       -1  \n",
       "228538      -1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View test data\n",
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       39978\n",
       "P       37890\n",
       "Y       36657\n",
       "A       36633\n",
       "R       33045\n",
       "U       32897\n",
       "M       32504\n",
       "X       32347\n",
       "C       32112\n",
       "H       31189\n",
       "Q       30145\n",
       "T       29723\n",
       "O       25610\n",
       "B       25212\n",
       "E       21871\n",
       "K       21676\n",
       "I       19805\n",
       "NONE    17930\n",
       "D       17284\n",
       "F       16721\n",
       "W        8268\n",
       "Z        5790\n",
       "S        4595\n",
       "G        3404\n",
       "V        3107\n",
       "J        1950\n",
       "L        1657\n",
       "Name: ord_4, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View categories in ord_4 column\n",
    "df.ord_4.fillna(\"NONE\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We define a value `rare` if it is less than 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       39978\n",
       "P       37890\n",
       "Y       36657\n",
       "A       36633\n",
       "R       33045\n",
       "U       32897\n",
       "M       32504\n",
       "X       32347\n",
       "C       32112\n",
       "H       31189\n",
       "Q       30145\n",
       "T       29723\n",
       "O       25610\n",
       "B       25212\n",
       "E       21871\n",
       "K       21676\n",
       "I       19805\n",
       "NONE    17930\n",
       "D       17284\n",
       "F       16721\n",
       "W        8268\n",
       "Z        5790\n",
       "S        4595\n",
       "RARE     3607\n",
       "G        3404\n",
       "V        3107\n",
       "Name: ord_4, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_4 = df.ord_4.fillna(\"NONE\")\n",
    "\n",
    "df.loc[\n",
    "    df[\"ord_4\"].value_counts()[df[\"ord_4\"]].values < 2000, \"ord_4\"\n",
    "] = \"RARE\"\n",
    "\n",
    "df.ord_4.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `create_folds.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_folds.py\n",
    "import pandas as pd \n",
    "from sklearn import model_selection\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # read training data\n",
    "    df = pd.read_csv(\"cat_train.csv\")\n",
    "    \n",
    "    # we create a new column called kfold and fill it with -1\n",
    "    df[\"kfold\"] = -1 \n",
    "    \n",
    "    # the next step is to randomize the rows of the data\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # fetch labels\n",
    "    y = df.target.values\n",
    "    \n",
    "    # initiate the kfold class from model_selection module\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    # fill the new kfold column\n",
    "    for f,(t_, v_) in enumerate(kf.split(X=df, y=y)):\n",
    "        df.loc[v_, 'kfold'] = f\n",
    "        \n",
    "    # save the new csv with kfold column\n",
    "    df.to_csv(\"cat_train_folds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209590</th>\n",
       "      <td>317929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>India</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>n</td>\n",
       "      <td>O</td>\n",
       "      <td>AI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503362</th>\n",
       "      <td>369652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Novice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i</td>\n",
       "      <td>K</td>\n",
       "      <td>ne</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192757</th>\n",
       "      <td>262650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>m</td>\n",
       "      <td>K</td>\n",
       "      <td>pT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369159</th>\n",
       "      <td>594242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>h</td>\n",
       "      <td>Q</td>\n",
       "      <td>oU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419410</th>\n",
       "      <td>439367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Star</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>China</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Warm</td>\n",
       "      <td>n</td>\n",
       "      <td>R</td>\n",
       "      <td>pT</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0      nom_1    nom_2  \\\n",
       "209590  317929    0.0    0.0    1.0     F     N   Red  Trapezoid  Axolotl   \n",
       "503362  369652    0.0    0.0    1.0     F     Y   Red     Circle      Dog   \n",
       "192757  262650    0.0    0.0    0.0     F     Y  Blue  Trapezoid     Lion   \n",
       "369159  594242    NaN    0.0    1.0     T     Y   Red  Trapezoid  Hamster   \n",
       "419410  439367    0.0    0.0    0.0     T     N  Blue       Star  Axolotl   \n",
       "\n",
       "             nom_3  ... ord_0        ord_1     ord_2 ord_3 ord_4 ord_5  day  \\\n",
       "209590       India  ...   1.0  Grandmaster      Cold     n     O    AI  1.0   \n",
       "503362  Costa Rica  ...   1.0       Novice       NaN     i     K    ne  7.0   \n",
       "192757     Finland  ...   1.0  Grandmaster      Cold     m     K    pT  1.0   \n",
       "369159     Finland  ...   3.0       Novice  Lava Hot     h     Q    oU  NaN   \n",
       "419410       China  ...   2.0       Novice      Warm     n     R    pT  6.0   \n",
       "\n",
       "       month target kfold  \n",
       "209590  12.0      1     1  \n",
       "503362   3.0      0     4  \n",
       "192757  12.0      0     1  \n",
       "369159  12.0      1     3  \n",
       "419410   2.0      0     3  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    120000\n",
       "3    120000\n",
       "2    120000\n",
       "1    120000\n",
       "0    120000\n",
       "Name: kfold, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check our new folds csv to see the number of samples per fold\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"cat_train_folds.csv\")\n",
    "\n",
    "df.kfold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    97536\n",
       "1    22464\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check target distribution per fold\n",
    "df[df.kfold==0].target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    97536\n",
       "1    22464\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.kfold==1].target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    97535\n",
       "1    22465\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.kfold==2].target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    97535\n",
       "1    22465\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.kfold==3].target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    97535\n",
       "1    22465\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.kfold==4].target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Simple Model*: One Hot Encoding + Logistic Regression\n",
    "\n",
    "### `ohe_logres.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786737590932164\n"
     ]
    }
   ],
   "source": [
    "# ohe_logres.py\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "def run(fold):\n",
    "    # load the full training data with folds\n",
    "    df = pd.read_csv(\"cat_train_folds.csv\")\n",
    "    \n",
    "    # all columns are features except id, target and kfold columns\n",
    "    features = [x for x in df.columns if x not in (\"id\", \"target\", \"kfold\")]\n",
    "    \n",
    "    # fill all NaN values with NONE\n",
    "    # note that all columns are converted to \"strings\"\n",
    "    # it doesn't matter because all are categories\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "        \n",
    "    # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    \n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    # initialize OneHotEncoder from scikit-learn\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    \n",
    "    # fit ohe on training + validation features\n",
    "    full_data = pd.concat(\n",
    "        [df_train[features], df_valid[features]], axis=0\n",
    "    )\n",
    "    ohe.fit(full_data[features])\n",
    "    \n",
    "    # transform training data\n",
    "    x_train = ohe.transform(df_train[features])\n",
    "    \n",
    "    # transform validation data\n",
    "    x_valid = ohe.transform(df_valid[features])\n",
    "    \n",
    "    # initialize Logistic Regression model\n",
    "    model = linear_model.LogisticRegression()\n",
    "    \n",
    "    # fit model on training data (ohe)\n",
    "    model.fit(x_train, df_train.target.values)\n",
    "    \n",
    "    # prediction on validation data\n",
    "    # we need probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # get roc_auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    \n",
    "    # print auc\n",
    "    print(auc)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # run function for fold = 0\n",
    "    # we can just replace this number and run this for any fold\n",
    "    run(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.786737590932164\n",
      "Fold = 1, AUC = 0.7864134324601486\n",
      "Fold = 2, AUC = 0.7891949604718245\n",
      "Fold = 3, AUC = 0.7865868586086606\n",
      "Fold = 4, AUC = 0.7841822012086013\n"
     ]
    }
   ],
   "source": [
    "# Change the code to run it for all folds\n",
    "# ohe_logres.py\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "def run(fold):\n",
    "    # load the full training data with folds\n",
    "    df = pd.read_csv(\"cat_train_folds.csv\")\n",
    "    \n",
    "    # all columns are features except id, target and kfold columns\n",
    "    features = [x for x in df.columns if x not in (\"id\", \"target\", \"kfold\")]\n",
    "    \n",
    "    # fill all NaN values with NONE\n",
    "    # note that all columns are converted to \"strings\"\n",
    "    # it doesn't matter because all are categories\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "        \n",
    "    # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    \n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    # initialize OneHotEncoder from scikit-learn\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    \n",
    "    # fit ohe on training + validation features\n",
    "    full_data = pd.concat(\n",
    "        [df_train[features], df_valid[features]], axis=0\n",
    "    )\n",
    "    ohe.fit(full_data[features])\n",
    "    \n",
    "    # transform training data\n",
    "    x_train = ohe.transform(df_train[features])\n",
    "    \n",
    "    # transform validation data\n",
    "    x_valid = ohe.transform(df_valid[features])\n",
    "    \n",
    "    # initialize Logistic Regression model\n",
    "    model = linear_model.LogisticRegression()\n",
    "    \n",
    "    # fit model on training data (ohe)\n",
    "    model.fit(x_train, df_train.target.values)\n",
    "    \n",
    "    # prediction on validation data\n",
    "    # we need probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # get roc_auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    \n",
    "    # print auc\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Another Model*: Label Encoding + Random Forest\n",
    "\n",
    "### `lbl_rf.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.7163084239682881\n",
      "Fold = 1, AUC = 0.7151674406595026\n",
      "Fold = 2, AUC = 0.7194365594431105\n",
      "Fold = 3, AUC = 0.7156918033989204\n",
      "Fold = 4, AUC = 0.7129110294100113\n"
     ]
    }
   ],
   "source": [
    "# lbl_rf.py\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def run(fold):\n",
    "    # load the full training data with folds\n",
    "    df = pd.read_csv(\"cat_train_folds.csv\")\n",
    "    \n",
    "    # all columns are features except id, target and kfold columns\n",
    "    features = [x for x in df.columns if x not in (\"id\", \"target\", \"kfold\")]\n",
    "    \n",
    "    # fill all NaN values with NONE\n",
    "    # note that all columns are converted to \"strings\"\n",
    "    # it doesn't matter because all are categories\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "        \n",
    "    # now its time to label encode the features\n",
    "    for col in features:\n",
    "        # initialize LabelEncoder for each column\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        \n",
    "        # fit label encoder on all data\n",
    "        lbl.fit(df[col])\n",
    "        \n",
    "        # transform all the data\n",
    "        df.loc[:, col] = lbl.transform(df[col])\n",
    "        \n",
    "    # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    \n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "      \n",
    "    # get training data\n",
    "    x_train = df_train[features].values\n",
    "    \n",
    "    # get validation data\n",
    "    x_valid = df_valid[features].values\n",
    "    \n",
    "    # initialize Random Forest model\n",
    "    model = ensemble.RandomForestClassifier(n_jobs=-1)\n",
    "    \n",
    "    # fit model on training data\n",
    "    model.fit(x_train, df_train.target.values)\n",
    "    \n",
    "    # prediction on validation data\n",
    "    # we need probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # get roc_auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    \n",
    "    # print auc\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Another model*: One Hot Encoding + fitting TruncatedSVD on sparse matrix with training + validation data\n",
    "\n",
    "### `ohe_svd_rf.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.707345889057882\n",
      "Fold = 1, AUC = 0.7056061509164883\n",
      "Fold = 2, AUC = 0.7093872850701919\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-a65e198d4a29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfold_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-59-a65e198d4a29>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(fold)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m# fit SVD on full sparse training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mfull_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0msvd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_sparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;31m# transform sparse training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtransformer\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \"\"\"\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    179\u001b[0m                 raise ValueError(\"n_components must be < n_features;\"\n\u001b[0;32m    180\u001b[0m                                  \" got %d >= %d\" % (k, n_features))\n\u001b[1;32m--> 181\u001b[1;33m             U, Sigma, VT = randomized_svd(X, self.n_components,\n\u001b[0m\u001b[0;32m    182\u001b[0m                                           \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                                           random_state=random_state)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36mrandomized_svd\u001b[1;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m     Q = randomized_range_finder(\n\u001b[0m\u001b[0;32m    350\u001b[0m         \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_random\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[0mpower_iteration_normalizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpower_iteration_normalizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36mrandomized_range_finder\u001b[1;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mpower_iteration_normalizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'LU'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpermute_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m             \u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpermute_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mpower_iteration_normalizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'QR'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'economic'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    558\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[0;32m    559\u001b[0m                              \"use '*' instead\")\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rmatmul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    469\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_multivector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;31m# csr_matvecs or csc_matvecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_matvecs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m         fn(M, N, n_vecs, self.indptr, self.indices, self.data,\n\u001b[0m\u001b[0;32m    490\u001b[0m            other.ravel(), result.ravel())\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ohe_svd_rf.py\n",
    "\n",
    "# lbl_rf.py\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn import decomposition\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def run(fold):\n",
    "    # load the full training data with folds\n",
    "    df = pd.read_csv(\"cat_train_folds.csv\")\n",
    "    \n",
    "    # all columns are features except id, target and kfold columns\n",
    "    features = [x for x in df.columns if x not in (\"id\", \"target\", \"kfold\")]\n",
    "    \n",
    "    # fill all NaN values with NONE\n",
    "    # note that all columns are converted to \"strings\"\n",
    "    # it doesn't matter because all are categories\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "        \n",
    "    # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    \n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    # initialize OneHotEncoder from scikit-learn\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "\n",
    "    # fit ohe on training + validation features\n",
    "    full_data = pd.concat(\n",
    "        [df_train[features], df_valid[features]], axis=0\n",
    "    )\n",
    "    ohe.fit(full_data[features])\n",
    "\n",
    "    # transform training data\n",
    "    x_train = ohe.transform(df_train[features])\n",
    "    \n",
    "    # transform validation data\n",
    "    x_valid = ohe.transform(df_valid[features])\n",
    "    \n",
    "    # initialize Truncated SVD\n",
    "    # we are reducing the data to 120 components\n",
    "    svd = decomposition.TruncatedSVD(n_components=120)\n",
    "    \n",
    "    # fit SVD on full sparse training data\n",
    "    full_sparse = sparse.vstack((x_train, x_valid))\n",
    "    svd.fit(full_sparse)\n",
    "\n",
    "    # transform sparse training data\n",
    "    x_train = svd.transform(x_train)\n",
    "    \n",
    "    # transform sparse validation data\n",
    "    x_valid = svd.transform(x_valid)\n",
    "    \n",
    "    # initialize Random Forest model\n",
    "    model = ensemble.RandomForestClassifier(n_jobs=-1)\n",
    "    \n",
    "    # fit model on training data (ohe)\n",
    "    model.fit(x_train, df_train.target.values)\n",
    "    \n",
    "    # prediction on validation data\n",
    "    # we need probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # get roc_auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    \n",
    "    # print auc\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Another Model*: Label Encoding + XGBoost\n",
    "\n",
    "### `lbl_xgb.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:35:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 0, AUC = 0.7627633684951625\n",
      "[00:37:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 1, AUC = 0.7625637056582746\n",
      "[00:40:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 2, AUC = 0.7636508512623847\n",
      "[00:42:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 3, AUC = 0.7625421350284056\n",
      "[00:45:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 4, AUC = 0.7606497734250544\n"
     ]
    }
   ],
   "source": [
    "# lbl_rf.py\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def run(fold):\n",
    "    # load the full training data with folds\n",
    "    df = pd.read_csv(\"cat_train_folds.csv\")\n",
    "    \n",
    "    # all columns are features except id, target and kfold columns\n",
    "    features = [x for x in df.columns if x not in (\"id\", \"target\", \"kfold\")]\n",
    "    \n",
    "    # fill all NaN values with NONE\n",
    "    # note that all columns are converted to \"strings\"\n",
    "    # it doesn't matter because all are categories\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "        \n",
    "    # now its time to label encode the features\n",
    "    for col in features:\n",
    "        # initialize LabelEncoder for each column\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        \n",
    "        # fit label encoder on all data\n",
    "        lbl.fit(df[col])\n",
    "        \n",
    "        # transform all the data\n",
    "        df.loc[:, col] = lbl.transform(df[col])\n",
    "        \n",
    "    # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    \n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "      \n",
    "    # get training data\n",
    "    x_train = df_train[features].values\n",
    "    \n",
    "    # get validation data\n",
    "    x_valid = df_valid[features].values\n",
    "    \n",
    "    # initialize XGBoost model\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_jobs=-1,\n",
    "        max_depth=7,\n",
    "        n_estimators=200\n",
    "    )\n",
    "    \n",
    "    # fit model on training data \n",
    "    model.fit(x_train, df_train.target.values)\n",
    "    \n",
    "    # prediction on validation data\n",
    "    # we need probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # get roc_auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    \n",
    "    # print auc\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
